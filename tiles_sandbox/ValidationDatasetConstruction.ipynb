{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a codon table\n",
    "CodonTable = {'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L', 'TCT': 'S', \n",
    "               'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'TAT': 'Y', 'TAC': 'Y', \n",
    "               'TGT': 'C', 'TGC': 'C', 'TGG': 'W', 'CTT': 'L', 'CTC': 'L', \n",
    "               'CTA': 'L', 'CTG': 'L', 'CCT': 'P', 'CCC': 'P', 'CCA': 'P', \n",
    "               'CCG': 'P', 'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q', \n",
    "               'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'ATT': 'I', \n",
    "               'ATC': 'I', 'ATA': 'I', 'ATG': 'M', 'ACT': 'T', 'ACC': 'T', \n",
    "               'ACA': 'T', 'ACG': 'T', 'AAT': 'N', 'AAC': 'N', 'AAA': 'K', \n",
    "               'AAG': 'K', 'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R', \n",
    "               'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V', 'GCT': 'A', \n",
    "               'GCC': 'A', 'GCA': 'A', 'GCG': 'A', 'GAT': 'D', 'GAC': 'D', \n",
    "               'GAA': 'E', 'GAG': 'E', 'GGT': 'G', 'GGC': 'G', 'GGA': 'G', \n",
    "               'GGG': 'G', 'TAG': '*', 'TAA': '*', 'TGA': '*'}\n",
    "available_codons = list(CodonTable.keys())\n",
    "\n",
    "ReverseCompDict = {\"A\": \"T\",\n",
    "                     \"T\": \"A\",\n",
    "                     \"C\": \"G\",\n",
    "                     \"G\": \"C\",\n",
    "                     \"N\": \"N\"}\n",
    "\n",
    "# Write a function that returns the reverse complement of a sequence\n",
    "def ReverseComplement(seq):\n",
    "\n",
    "    # Loop through the sequence in reverse and translate\n",
    "    return \"\".join(ReverseCompDict[char] for char in reversed(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original point of this notebook was to create specific datasets for passing into ssSeq with NNN indicating mutation positions, validating ssSeq's effectiveness. The updates in this notebook are to generate a dataset with specified mutations spread throughout the reference sequence. Using this known data set we can then test the ssSeq_tiles_branch for the ability to run without specifying mutation positions. We will be creating data to test the below:\n",
    "\n",
    "1. Do we get the expected alignment frequencies and counts when passing in imperfect fastq files (i.e. some bases have Q-scores < 30).\n",
    "2. What happens if we add insertions or deletions to our reads?\n",
    "3. What happens in all of the above cases in troubleshoot mode vs regular mode?\n",
    "4. What happens in all of the above cases using a detailed refseq file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generating the reference sequences. ~~Each reference sequence has 4 positions in it. The below types of reference sequence are prepared for 150 bp reads:~~\n",
    "\n",
    "~~1. 3 in forward read, 1 in reverse.~~\n",
    "~~2. 2 in forward, 2 in reverse.~~\n",
    "~~3. 1 in forward, 3 in reverse.~~\n",
    "\n",
    "For the tile based approach there is only one reference sequence, the parent sequence. I am using P411 C10 as the reference sequence here, looking at tile 1 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generic reference sequence\n",
    "full_P411_seq = \"ATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTTAAATTCGAGGCGCCTGGTCGTGTAACGCGCTACTTATCAAGTCAGCGTCTAATTAAAGAAGCATGCGATGAATCACGCTTTGATAAAGAGTTAAGTCAAGGTCTGAAATTTCTGCGTGATTTTCTTGGAGACGGGTTAGCCACAAGCTGGACGCATGAAAAAAATTGGAAAAAAGCGCATAATATCTTACTTCCAAGCTTTAGTCAGCAGGCAATGAAAGGCTATCATGCGAGTATGGTCGATATCGCCGTGCAGCTTGTTCAAAAGTGGGAGCGTCTAAATGCAGATGAGCATATTGAAGTATCGGAAGACATGACACGTTTAACGCTTGATACAATTGGTCTTTGCGGCTTTAACTATCGCCTTAACAGCTTTTACCGAGATCAGCCTCATCCATTTATTATAAGTCTGGTCCGTGCACTGGATGAAGTAATGAACAAGCTGCAGCGAGCAAATCCAGACGACCCAGCTTATGATGAAAACAAGCGCCAGTTTCAAGAAGATATCAAGGTGATGAACGACCTAGTAGATAAAATTATTGCAGATCGCAAAGCAAGGGGTGAACAAAGCGATGATTTATTAACGCAGATGCTAAACGGAAAAGATCCAGAAACGGGTGAGCCGCTTGATGACGGGAACATTCGCTATCAAATTATTACATTCTTATATGCGGGAGTTGAAGGTACAAGTGGTCTTTTATCATTTGCGCTGTATTTCTTAGTGAAAAATCCACATGTATTACAAAAAGTAGCAGAAGAAGCAGCACGAGTTCTAGTAGATCCTGTTCCAAGCTACAAACAAGTCAAACAGCTTAAATATGTCGGCATGGTCTTAAACGAAGCGCTGCGCTTATGGCCAACGGTTCCTTATTTTTCCCTATATGCAAAAGAAGATACGGTGCTTGGAGGAGAATATCCTTTAGAAAAAGGCGACGAAGTAATGGTTCTGATTCCTCAGCTTCACCGTGATAAAACAGTTTGGGGAGACGATGTGGAGGAGTTCCGTCCAGAGCGTTTTGAAAATCCAAGTGCGATTCCGCAGCATGCGTTTAAACCGTTTGGAAACGGTCAGCGTGCGTCTCTGGGTCAGCAGTTCGCTCTTCATGAAGCAACGCTGGTACTTGGTATGATGCTAAAACACTTTGACTTTGAAGATCATACAAACTACGAGCTCGATATTAAAGAACTGCAGACGTTAAAACCTAAAGGCTTTGTGGTAAAAGCAAAATCGAAAAAAATTCCGCTTGGCGGTATTCCTTCACCTAGCACTGAACAGTCTGCTAAAAAAGTACGCAAAAAGGCAGAAAACGCTCATAATACGCCGCTGCTTGTGCTATACGGTTCAAATATGGGTACCGCTGAAGGAACGGCGCGTGATTTAGCAGATATTGCAATGAGCAAAGGATTTGCACCGCAGGTCGCAACGCTTGATTCACACGCCGGAAATCTTCCGCGCGAAGGAGCTGTATTAATTGTAACGGCGTCTTATAACGGTCATCCGCCTGATAACGCAAAGCAATTTGTCGACTGGTTAGACCAAGCGTCTGCTGATGAAGTAAAAGGCGTTCGCTACTCCGTATTTGGATGCGGCGATAAAAACTGGGCTACTACGTATCAAAAAGTGCCTGCTTTTATCGATGAAACGCTTGCCGCTAAAGGGGCAGAAAACATCGCTGACCGCGGTGAAGCAGATGCAAGCGACGACTTTGAAGGCACATATGAAGAATGGCGTGAACATATGTGGAGTGACGTAGCAGCCTACTTTAACCTCGACATTGAAAACAGTGAAGATAATAAATCTACTCTTTCACTTCAATTTGTCGACAGCGCCGCGGATATGCCGCTTGCGAAAATGCACGGTGCGTTTTCAACGCTCGAGCACCACCACCACCACCACTGA\"\n",
    "\n",
    "#Define reference sequence as just the first tile (plus overlap regions)\n",
    "ref_seq = \"ATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTTAAATTCGAGGCGCCTGGTCGTGTAACGCGCTACTTATCAAGTCAGCGTCTAATTAAAGAAGCATGCGATGAATCACG\"\n",
    "baseline_quality = \"\".join(\"@\" for _ in range(len(ref_seq)))\n",
    "\n",
    "# # Define the positions of \"NNN\" in each of the desired reference sequences\n",
    "# pos1 = [9, 57, 111, 167]\n",
    "# pos2 = [57, 111, 168, 201]\n",
    "# pos3 = [111, 168, 201, 234]\n",
    "# position_lists = [pos1, pos2, pos3]\n",
    "\n",
    "# # Build the additional reference sequences\n",
    "# other_refs = [None for _ in range(3)]\n",
    "# for i, pos_list in enumerate(position_lists):\n",
    "#     other_refs[i] = (ref_seq[:pos_list[0]] + \"NNN\" + ref_seq[pos_list[0] + 3: pos_list[1]] +\n",
    "#                      \"NNN\" + ref_seq[pos_list[1] + 3 : pos_list[2]] +\n",
    "#                      \"NNN\" + ref_seq[pos_list[2] + 3 : pos_list[3]] + \n",
    "#                      \"NNN\" + ref_seq[pos_list[3] + 3:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reference sequences built we can get on to making the fake fastq files. This is done in the below code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108, 180, 177,  27, 123,  15,  90,  87,  33, 135])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DI01',\n",
       "  'A01',\n",
       "  'GATCATG',\n",
       "  'GAACTGC',\n",
       "  83,\n",
       "  'GATCATGCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'GAACTGCGGTAGACGGAGACAGGCGGCGTGATTCATCCGTTGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'T',\n",
       "  186,\n",
       "  62),\n",
       " ('DI01',\n",
       "  'A02',\n",
       "  'TACATGG',\n",
       "  'ACCAGGT',\n",
       "  63,\n",
       "  'TACATGGCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAAAAAGGAGAAATCTTT',\n",
       "  'ACCAGGTGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTTTTTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'K',\n",
       "  108,\n",
       "  36),\n",
       " ('DI01',\n",
       "  'A03',\n",
       "  'AAGCACC',\n",
       "  'TCTAGAG',\n",
       "  40,\n",
       "  'AAGCACCCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATGGGGAGAAATCTTT',\n",
       "  'TCTAGAGGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCCCATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'W',\n",
       "  108,\n",
       "  36),\n",
       " ('DI01',\n",
       "  'A04',\n",
       "  'TGGCTCA',\n",
       "  'CACACAA',\n",
       "  76,\n",
       "  'TGGCTCACACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGCCGGAATTAGGAGAAATCTTT',\n",
       "  'CACACAAGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCCGGCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'P',\n",
       "  102,\n",
       "  34),\n",
       " ('DI01',\n",
       "  'A05',\n",
       "  'CTTGCTC',\n",
       "  'GTGGAAC',\n",
       "  29,\n",
       "  'CTTGCTCCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'GTGGAACGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCCCTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'G',\n",
       "  147,\n",
       "  49),\n",
       " ('DI01',\n",
       "  'A06',\n",
       "  'GAAGCGT',\n",
       "  'ATATGCC',\n",
       "  87,\n",
       "  'GAAGCGTCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCGTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'ATATGCCGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'R',\n",
       "  18,\n",
       "  6),\n",
       " ('DI01',\n",
       "  'A07',\n",
       "  'TCTCCAT',\n",
       "  'GGTCTGA',\n",
       "  76,\n",
       "  'TCTCCATCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCCCG',\n",
       "  'GGTCTGAGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTCGGGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'P',\n",
       "  120,\n",
       "  40),\n",
       " ('DI01',\n",
       "  'A08',\n",
       "  'TTGAAGG',\n",
       "  'GTGAGAT',\n",
       "  50,\n",
       "  'TTGAAGGCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'GTGAGATGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAAGAGAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'L',\n",
       "  123,\n",
       "  41),\n",
       " ('DI01',\n",
       "  'A09',\n",
       "  'GAATGTC',\n",
       "  'TTGGCAG',\n",
       "  51,\n",
       "  'GAATGTCCACCCAAGACCACTCTCCGGATGACAATTAAAGAAATTCCTCAGCCAAAAACGTTTGGAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'TTGGCAGGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'I',\n",
       "  15,\n",
       "  5),\n",
       " ('DI01',\n",
       "  'A10',\n",
       "  'ATCTCCA',\n",
       "  'ATGCCTG',\n",
       "  24,\n",
       "  'ATCTCCACACCCAAGACCACTCTCCGGATGACAATTAAAGAAATGCCTCAGCCAAAAACGTTTGAAGAGCTTAAAAATTTACCGTTATTAAACACAGATAAACCGGTTCAAGCTTTGATGAAAATTGCGGATGAATTAGGAGAAATCTTT',\n",
       "  'ATGCCTGGGTAGACGGAGACAGGCGGCGTGATTCATCGCATGCTTCTTTAATTAGACGCTGACTTGATAAGTAGCGCGTTACACGACCAGGCGCCTCGAATTTAAAGATTTCTCCTAATTCATCCGCAATTTTCATCAAAGCTTGAACCG',\n",
       "  'E',\n",
       "  36,\n",
       "  12)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed\n",
    "np.random.seed(2)\n",
    "\n",
    "# First load the barcode sequences.\n",
    "barcode_df = pd.read_csv(\"../ssSeqSupport/IndexMap.csv\")\n",
    "\n",
    "# Define the adapter sequences\n",
    "f_adapter = \"CACCCAAGACCACTCTCCGG\"\n",
    "r_adapter = \"GGTAGACGGAGACAGGCGG\"\n",
    "\n",
    "# Quality options\n",
    "quality_opts = [\">\", \"?\", \"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "qual_to_score = {\"=\": 28, \">\": 29, \"?\": 30, \"A\": 31,\n",
    "                 \"B\": 32, \"C\": 33, \"D\": 34, \"E\": 35}\n",
    "\n",
    "# No position sets, removing the loop through position sets.\n",
    "\n",
    "\n",
    "# Now loop over each barcode row\n",
    "updated_bc_info = [None for _ in range(len(barcode_df))]\n",
    "for k, (_, row) in enumerate(barcode_df.iterrows()):\n",
    "\n",
    "    # Select 1 codon at random\n",
    "    codon_choice = np.random.choice(available_codons, size = 2, replace = False)[0]\n",
    "    aa_choice = CodonTable[codon_choice]\n",
    "\n",
    "    #Select 1 amino acid position at random from within the reference sequence\n",
    "    #Floor division by three and multiplied by three to remain within frame\n",
    "    aa_mut_position = np.random.choice(len(ref_seq)//3, 1)\n",
    "    nt_mut_position = aa_mut_position * 3\n",
    "    \n",
    "    \n",
    "    #print(pos_list, codon_choices, aa_choices, aa_mut_position)\n",
    "    #modify here to choose a random position within the reference sequence\n",
    "    # Construct all gene sequences\n",
    "    new_seq = (ref_seq[:nt_mut_position[0]] + codon_choice + ref_seq[nt_mut_position[0] + 3:])\n",
    "\n",
    "    # Generate actual fake read sequences\n",
    "    f_seq = row[\"F-BC\"] + f_adapter + new_seq[:123]\n",
    "    r_seq = row[\"R-BC\"] + r_adapter + ReverseComplement(new_seq[-124:])\n",
    "\n",
    "    # Generate a number at random which dictates the number of sequences we will see for the row\n",
    "    n_seqs = np.random.randint(0, 101)\n",
    "\n",
    "    # Record all information\n",
    "    updated_bc_info[k] = (row.IndexPlate, row.Well, row[\"F-BC\"], row[\"R-BC\"], n_seqs, \n",
    "                          f_seq, r_seq, aa_choice, nt_mut_position[0], aa_mut_position[0])\n",
    "\n",
    "# removing bc_info_by_pos, looking only at updated_bc_info now\n",
    "updated_bc_info[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "# Define the forward and reverse fastq file strings\n",
    "fstring = \"\"\n",
    "rstring = \"\"\n",
    "\n",
    "# Define a list for holding information about each read\n",
    "#Adding the position as a part of information and removing additional position mutation\n",
    "read_list = [[\"IndexPlate\", \"Well\", \"F-BC\", \"R-BC\", \"AApos\", \"NTmutpos\", \"AAmutpos\", \"Q1\"]]\n",
    "\n",
    "# Build actual fastq files\n",
    "#modified to include aa choice and aa position (aa_mut_position) from previous block\n",
    "for i, (index_plate, well, fbc, rbc, nseqs, fseq, rseq, aachoice, ntpos, aapos) in enumerate(updated_bc_info):\n",
    "\n",
    "    # Loop over the number of sequences\n",
    "    for j in range(nseqs):\n",
    "\n",
    "        # Select 4 sets of quality scores at random\n",
    "        qual_choice = np.random.choice(quality_opts, size = (1, 3), replace = True)[0]\n",
    "        qual_string = \"\".join(qual_choice)\n",
    "\n",
    "        #print(qual_choice, qual_string)\n",
    "        \n",
    "        # Calculate whether all characters in string give a quality above 30/equal to 30 or not        \n",
    "        greater30 = [qual_to_score[character]>=30 for character in qual_string]\n",
    "\n",
    "        # Generate quality scores \n",
    "        quality_scores = (baseline_quality[:ntpos] + qual_string + \n",
    "                          baseline_quality[ntpos + 3:])\n",
    "\n",
    "        # Generate fake quality scores\n",
    "        f_qual = \"@\"*27 + quality_scores[:123]\n",
    "        r_qual = \"@\"*26 + quality_scores[-124:][::-1]\n",
    "\n",
    "        # Build the fastq entries\n",
    "        uid = \"@M06418:33:000000000-CRL6Y:1:1101:{}:{} 1:N:0:162\".format(i, j)\n",
    "\n",
    "        # Add to the forward entry\n",
    "        if i==0 and j==0:\n",
    "            fstring += uid\n",
    "        else:\n",
    "            fstring += \"\\n\" + uid\n",
    "        fstring += \"\\n\" + fseq\n",
    "        fstring += \"\\n+\"\n",
    "        fstring += \"\\n\" + f_qual\n",
    "\n",
    "        # Add to the reverse entry\n",
    "        if i==0 and j==0:\n",
    "            rstring += uid\n",
    "        else:\n",
    "            rstring += \"\\n\" + uid\n",
    "        rstring += \"\\n\" + rseq\n",
    "        rstring += \"\\n+\"\n",
    "        rstring += \"\\n\" + r_qual\n",
    "\n",
    "        # Append to the read list\n",
    "        read_list.append([index_plate, well, fbc, rbc, aachoice, ntpos, aapos, *greater30])\n",
    "\n",
    "# Save everything\n",
    "with open(\"P411_Tile1_R1_test.fastq\".format(k+1), \"w\") as f:\n",
    "    f.write(fstring)\n",
    "with open(\"P411_Tile1_R2_test.fastq\".format(k+1), \"w\") as f:\n",
    "    f.write(rstring)\n",
    "with open(\"P411_Tile1_SequenceInfo.csv\".format(k+1), \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(read_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that on running, as of 01/09/2020, the pos0 and pos4 cannot be run on ssSeq. This is because the software cannot currently handle having no variable regions in either the forward or reverse direction. Pos1 through pos3 were run on 01/09/2020, however, and are analyzed below. The appropriate files for these position sets can be found in \"Set1\" in the same folder of this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate01-0_SummaryInfo.csv' does not exist: b'/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate01-0_SummaryInfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d0c3bf6a263e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate0{}-0_SummaryInfo.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Load the sequence info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate01-0_SummaryInfo.csv' does not exist: b'/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate01-0_SummaryInfo.csv'"
     ]
    }
   ],
   "source": [
    "# Load the results file\n",
    "all_data = pd.DataFrame()\n",
    "for i in range(1, 9):\n",
    "    all_data = all_data.append(pd.read_csv(\"/home/brucejwittmann/GitRepos/ssSeq/ssSeq_Output/20200109-171117/Summaries/TestPlate0{}-0_SummaryInfo.csv\".format(i)))\n",
    "    \n",
    "# Load the sequence info\n",
    "sequence_info = pd.read_csv(\"./Set1/Pos1/Pos1_SequenceInfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequence_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-9621c20587e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msequence_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sequence_info' is not defined"
     ]
    }
   ],
   "source": [
    "sequence_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique plate-well combos\n",
    "plate_well = tuple(set(tuple(zip(sequence_info.IndexPlate.values, sequence_info.Well.values))))\n",
    "\n",
    "# Get the expected depth for each site in each well\n",
    "count_info = []\n",
    "for plate, well in plate_well:\n",
    "    \n",
    "    # Pull all instances where plate is plate and well is well\n",
    "    subdf = sequence_info.loc[(sequence_info.IndexPlate==plate)&(sequence_info.Well==well), \n",
    "                              [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]]\n",
    "    AAs = sequence_info.loc[(sequence_info.IndexPlate==plate)&(sequence_info.Well==well), \n",
    "                              [\"AA1\", \"AA2\", \"AA3\", \"AA4\"]].values[0]\n",
    "    \n",
    "    # Count the expected read depth per well\n",
    "    read_depths = subdf.values.sum(axis=0)\n",
    "    \n",
    "    # Append to count_info\n",
    "    sites = [1, 2, 3, 1]\n",
    "    directions = [\"Forward\", \"Forward\", \"Forward\", \"Reverse\"]\n",
    "    for i, count in enumerate(read_depths):\n",
    "        count_info.append([plate, well, sites[i], directions[i], float(count), AAs[i]])\n",
    "        \n",
    "# Convert count_info into a dataframe\n",
    "count_df = pd.DataFrame(count_info, columns = [\"Plate\", \"Well\", \"Site\", \"ReadDirection\", \"ExpectedDepth\", \"ExpectedAA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge the count_df onto the all_data df\n",
    "complete_df = all_data.merge(count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything worked as expected, each well should call the appropriate amino acid along with the appropriate read depth. This is checked below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(complete_df.ExpectedDepth == complete_df.WellSeqDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(complete_df.ExpectedAA == complete_df.AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case of Pos1, we thus are calling both the read depth and amino acid correctly. Now what if we have overlapping positions in forward and reverse. Do we call these correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
