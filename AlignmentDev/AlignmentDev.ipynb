{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a development ground for the new alignment protocol. Note that the clustal omega version being used was downloaded on 10/26/2020 from \"http://www.clustal.org/omega/\" and was renamed to \"clustalo\" from the binary file clustalo-1.2.4-Ubuntu-x86_64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary modules\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align.Applications import ClustalOmegaCommandline\n",
    "from Bio import pairwise2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BARCODE_LENGTH = 7\n",
    "ADAPTER_LENGTH_F = 20\n",
    "ADAPTER_LENGTH_R = 19\n",
    "\n",
    "# Redefine the BioPython aligment function so that we can quicky change\n",
    "# parameters later\n",
    "def deseq_align(reference, query):\n",
    "    \n",
    "    # Redefine biopython aligment function (this is just for code neatness)\n",
    "    return pairwise2.align.globalxs(reference, query, open = -2, extend = -1,\n",
    "                                    one_alignment_only=True, penalize_end_gaps = False)[0]\n",
    "    \n",
    "\n",
    "# Define an object that holds BioPython SeqRecords\n",
    "class SeqPair():\n",
    "    \n",
    "    # Record that we don't have forward or reverse information yet. Record that\n",
    "    # we don't have alignment information yet\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Did sequence pass QC?\n",
    "        self._use_f = False\n",
    "        self._use_r = False\n",
    "        \n",
    "        # Did alignments pass QC?\n",
    "        self._use_f_alignment = False\n",
    "        self._use_r_alignment = False\n",
    "    \n",
    "    # Assign forward reads\n",
    "    def assign_f(self, f_record):\n",
    "        \n",
    "        # Build summary stats\n",
    "        self._f_barcode, self._f_len, self._f_average_q = self.calculate_read_stats(f_record)\n",
    "                \n",
    "        # Assign the forward barcode and the adapterless sequence\n",
    "        self._f_adapterless = f_record[(BARCODE_LENGTH + ADAPTER_LENGTH_F):]\n",
    "        \n",
    "        # Note that we have forward information\n",
    "        self._use_f = True\n",
    "    \n",
    "    # Assign a paired reverse read\n",
    "    def assign_r(self, r_record):\n",
    "        \n",
    "        # Build summary stats\n",
    "        self._r_barcode, self._r_len, self._r_average_q = self.calculate_read_stats(r_record)\n",
    "        \n",
    "        # Assign the reverse barcode and adapterless sequence. \n",
    "        # We want to have the reverse complement of this sequence to match\n",
    "        # the reference sequence\n",
    "        sliced_r = r_record[(BARCODE_LENGTH + ADAPTER_LENGTH_R):]\n",
    "        self._r_adapterless = sliced_r.reverse_complement(id = True, description = True)\n",
    "        \n",
    "        # Note that we have reverse information\n",
    "        self._use_r = True\n",
    "        \n",
    "    # Calculate summary stats for a read\n",
    "    def calculate_read_stats(self, record):\n",
    "        \n",
    "        # Calculate relevant summary stats needed by both forward and reverse methods\n",
    "        barcode = str(record.seq)[:BARCODE_LENGTH]\n",
    "        length = len(record)\n",
    "        average_quality = np.mean(record.letter_annotations[\"phred_quality\"])\n",
    "        \n",
    "        return barcode, length, average_quality\n",
    "    \n",
    "    # Write a function that performs QC on reads\n",
    "    def qc_reads(self, length_filter, q_cutoff):\n",
    "        \n",
    "        # Make sure forward reads pass the length and quality cutoff. Only run QC\n",
    "        # if we actually recorded a forward read.\n",
    "        if self._use_f:\n",
    "            if self.f_len < length_filter or self.f_average_q < q_cutoff:\n",
    "                self._use_f = False\n",
    "                \n",
    "        # Make sure reverse reads pass the length and quality cutoff. Only run QC\n",
    "        # if we actually recorded a forward read.\n",
    "        if self._use_r:\n",
    "            if self.r_len < length_filter or self._r_average_q < q_cutoff:\n",
    "                self._use_r = False\n",
    "    \n",
    "    # Align forward and reverse reads to a reference sequence\n",
    "    def align(self, reference):\n",
    "        \n",
    "        # Make a pairwise alignment. Only align the reads we are using.\n",
    "        if is_paired():\n",
    "            self._f_alignment = deseq_align(reference, self.f_adapterless.seq)\n",
    "            self._r_alignment = deseq_align(reference, self.r_adapterless.seq)\n",
    "            \n",
    "        # If we are only using forward read, handle this here\n",
    "        elif self.use_f:\n",
    "            self._f_alignment = deseq_align(reference, self.f_adapterless.seq)\n",
    "            \n",
    "        # If we are only using reverse read, handle this here\n",
    "        elif self.use_r:\n",
    "            self._r_alignment = deseq_align(reference, self.r_adapterless.seq)\n",
    "            \n",
    "        else:\n",
    "            raise AssertionError(\"No reads to align in reference.\")\n",
    "        \n",
    "    # Write a function that runs QC on an alignment. We automatically discard an alignment\n",
    "    # with an insertion or deletion. \n",
    "    def qc_alignments(self):\n",
    "        pass\n",
    "        \n",
    "    # Write a function for extracting information from the alignment\n",
    "    def analyze_alignment(self):\n",
    "        pass\n",
    "    \n",
    "    # Write a function that returns read lengths\n",
    "    def read_lengths(self):\n",
    "        if self.is_paired():\n",
    "            return [self.f_len, self.r_len]\n",
    "        elif self.use_f:\n",
    "            return [self.f_len, np.nan]\n",
    "        elif self.use_r:\n",
    "            return [np.nan, self.r_len]\n",
    "        else:\n",
    "            raise AssertionError(\"No reads for which to return lengths.\")\n",
    "    \n",
    "    # Check to see if we are using both sequences\n",
    "    def is_paired(self):\n",
    "        if self.use_r and self.use_f:\n",
    "            return True\n",
    "        \n",
    "    # Check to see if we have no sequences aligned\n",
    "    def is_dud(self):\n",
    "        if not (self.use_r or self.use_f):\n",
    "            return True\n",
    "        \n",
    "    # Make all the properties\n",
    "    @property\n",
    "    def use_f(self):\n",
    "        return self._use_f\n",
    "    \n",
    "    @property\n",
    "    def use_r(self):\n",
    "        return self._use_r\n",
    "    \n",
    "    @property\n",
    "    def use_f_alignment(self):\n",
    "        return self._use_f_alignment\n",
    "    \n",
    "    @property\n",
    "    def use_r_alignment(self):\n",
    "        return self._use_r_alignment\n",
    "    \n",
    "    @property\n",
    "    def f_barcode(self):\n",
    "        return self._f_barcode\n",
    "    \n",
    "    @property\n",
    "    def f_len(self):\n",
    "        return self._f_len\n",
    "    \n",
    "    @property\n",
    "    def f_average_q(self):\n",
    "        return self._f_average_q\n",
    "    \n",
    "    @property\n",
    "    def f_adapterless(self):\n",
    "        return self._f_adapterless\n",
    "    \n",
    "    @property\n",
    "    def r_barcode(self):\n",
    "        return self._r_barcode\n",
    "    \n",
    "    @property\n",
    "    def r_len(self):\n",
    "        return self._r_len\n",
    "    \n",
    "    @property\n",
    "    def r_average_q(self):\n",
    "        return self._r_average_q\n",
    "    \n",
    "    @property\n",
    "    def r_adapterless(self):\n",
    "        return self._r_adapterless\n",
    "        \n",
    "    @property\n",
    "    def orphan(self):\n",
    "        return self._orphan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading forward reads...\n",
      "Loading reverse reads...\n"
     ]
    }
   ],
   "source": [
    "# Write a function for loading and pairing fastq files\n",
    "def load_fastq(f_loc, r_loc):\n",
    "\n",
    "    # Create a dictionary that links id to sequence object\n",
    "    id_to_reads = {}\n",
    "    print(\"Loading forward reads...\")\n",
    "    all_f_recs = list(SeqIO.parse(f_loc, \"fastq\"))\n",
    "    id_to_reads = {f_record.id: SeqPair().assign_f(f_record) for f_record in all_f_recs}\n",
    "    \n",
    "    # Associate reverse reads with the forward\n",
    "    print(\"Loading reverse reads...\")\n",
    "    all_r_recs = list(SeqIO.parse(r_loc, \"fastq\"))\n",
    "    for r_record in all_r_recs:\n",
    "\n",
    "        # If there is no partern in id_to_reads, continue\n",
    "        if r_record.id not in id_to_reads:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, attach the reverse record\n",
    "        else:\n",
    "            id_to_reads[r_record.id].assign_r(r_record)\n",
    "            \n",
    "    # Only keep records that have a partner\n",
    "    return list(id_to_reads.values())\n",
    "\n",
    "# Load fastq files\n",
    "all_seqpairs = load_fastq(\"./TestData/20200205_ssSeq/CHL2_S199_L001_R1_001.fastq\",\n",
    "                          \"./TestData/20200205_ssSeq/CHL2_S199_L001_R2_001.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([3.]), count=array([2.]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [[1, 3],\n",
    "            [5, np.nan],\n",
    "            [0, 3]]\n",
    "ss.mode(test_list, axis = None, nan_policy = \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for filtering out bad seqpairs\n",
    "def qc_seqpairs(all_seqpairs, read_length = None, length_cutoff = 0.9, q_cutoff = 30):\n",
    "    \n",
    "    # If we don't have the read length determine it\n",
    "    if read_length is None:\n",
    "\n",
    "        # Get the most common read length. We will assign this as our read length\n",
    "        all_readlengths = np.array([seqpair.read_lengths() for seqpair in no_orphans])\n",
    "        read_length = ss.mode(all_readlengths, axis = None, nan_policy = \"omit\").mode[0]\n",
    "\n",
    "    # Filter out seqpairs that are too short. Both pairs must pass for this \n",
    "    # condition to be met\n",
    "    length_filter = int(read_length * length_cutoff)\n",
    "    no_short = list(filter(lambda x: (x.r_len >= length_filter and x.f_len >= length_filter), no_orphans))\n",
    "\n",
    "    # Filter out pairs that have a bad quality score. These are what will be returned.\n",
    "    no_bad_q = list(filter(lambda x: (x.r_average_q >= q_cutoff and x.f_average_q >= q_cutoff), no_short))\n",
    "\n",
    "    # Eliminate any duds, which are those seqpairs with both a forward and a reverse that failed qc\n",
    "    no_orphans = list(filter(lambda x: not x.is_dud(), all_seqpairs))\n",
    "    \n",
    "    return no_bad_q\n",
    "\n",
    "filtered_seqpairs = filter_bad_seqpairs(all_seqpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_WELLS = {'A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', \n",
    "                 'A10', 'A11', 'A12', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                 'B07', 'B08', 'B09', 'B10', 'B11', 'B12', 'C01', 'C02', 'C03', \n",
    "                 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', \n",
    "                 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', \n",
    "                 'D10', 'D11', 'D12', 'E01', 'E02', 'E03', 'E04', 'E05', 'E06', \n",
    "                 'E07', 'E08', 'E09', 'E10', 'E11', 'E12', 'F01', 'F02', 'F03', \n",
    "                 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11', 'F12', \n",
    "                 'G01', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09', \n",
    "                 'G10', 'G11', 'G12', 'H01', 'H02', 'H03', 'H04', 'H05', 'H06', \n",
    "                 'H07', 'H08', 'H09', 'H10', 'H11', 'H12'}\n",
    "\n",
    "# Load the index map and reference sequencefile\n",
    "index_map = pd.read_csv(\"/home/brucejwittmann/GitRepos/ssSeq/ssSeqSupport/IndexMap.csv\")\n",
    "ref_seq_crude = pd.read_csv(\"/home/brucejwittmann/GitRepos/ssSeq/AlignmentDev/TestData/20200205_ssSeq/RefSeqs.csv\")\n",
    "\n",
    "# Expand each reference sequence\n",
    "updated_ref_array = []\n",
    "for row in ref_seq_crude.itertuples(index = False):\n",
    "    updated_ref_array.extend([[row.PlateName, row.IndexPlate, well, row.ReferenceSequence]\n",
    "                             for well in ALLOWED_WELLS])\n",
    "    \n",
    "# Define the complete reference sequence dataframe\n",
    "complete_ref_seq = pd.DataFrame(updated_ref_array, columns = (\"PlateName\", \"IndexPlate\", \"Well\", \"ReferenceSequence\"))\n",
    "\n",
    "# Join on plate and well\n",
    "merged_dfs = complete_ref_seq.merge(index_map, on = (\"IndexPlate\", \"Well\"))\n",
    "\n",
    "# Map barcode to reference sequence, plate, and well\n",
    "bc_to_ref_plate_well = {(row.FBC, row.RBC): {\"IndexPlate\": row.IndexPlate,\n",
    "                                             \"PlateNickname\": row.PlateName,\n",
    "                                             \"Well\": row.Well,\n",
    "                                             \"ReferenceSequence\": row.ReferenceSequence}\n",
    "                       for row in merged_dfs.itertuples(index = False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Well():\n",
    "    \n",
    "    # Initialization assigns attributes, reference sequences, and sequence pairs\n",
    "    def __init__(self, seqpairs, refseq_df_info, save_dir):\n",
    "        \n",
    "        # Assign the sequence pairs as an attribute and unpack the refseq info\n",
    "        self._seqpairs = seqpairs\n",
    "        self._index_plate = refseq_df_info[\"IndexPlate\"]\n",
    "        self._plate_nickname = refseq_df_info[\"PlateNickname\"]\n",
    "        self._well = refseq_df_info[\"Well\"]\n",
    "        self._reference_sequence = refseq_df_info[\"ReferenceSequence\"]\n",
    "        \n",
    "        # Generate save locations for alignment files\n",
    "        self._fasta_loc = os.path.join(save_dir, \"ParsedFilteredFastas\", \n",
    "                                       f\"{self.index_plate}-{self.well}.fasta\")\n",
    "        self._msa_loc = os.path.join(save_dir, \"Msas\", \n",
    "                                       f\"{self.index_plate}-{self.well}.fasta\")\n",
    "        \n",
    "    # Write a function that outputs fasta files for all of the seqpairs\n",
    "    def write_fastas(self):\n",
    "        \n",
    "        # Write a reference sequence\n",
    "        reference = SeqRecord(Seq(self.reference_sequence),\n",
    "                              id = \"reference\",\n",
    "                              description = \"reference\")\n",
    "        \n",
    "        # Build a list of sequences to save\n",
    "        counter = 1\n",
    "        records_to_save = [None for _ in range(len(self.seqpairs) * 2 + 1)]\n",
    "        records_to_save[0] = reference\n",
    "        for seqpair in self.seqpairs:\n",
    "\n",
    "            # Save the sequnece objects\n",
    "            records_to_save[counter] = seqpair.f_adapterless\n",
    "            records_to_save[counter + 1] = seqpair.r_adapterless\n",
    "\n",
    "            # Update counter\n",
    "            counter += 2\n",
    "            \n",
    "        # Save the records\n",
    "        with open(self.fasta_loc, \"w\") as f:\n",
    "            SeqIO.write(records_to_save, f, \"fasta\")\n",
    "    \n",
    "    # Write a function that uses Clustal Omega to make an MSA of the alignment\n",
    "    def align_msa(self):\n",
    "        \n",
    "        # Run clustal omega as a subprocess\n",
    "        ccla = ClustalOmegaCommandline(infile = self.fasta_loc, clustersize = len(self.seqpairs),\n",
    "                                       outfile = self.msa_loc, auto = True, force = True, verbose = True)\n",
    "        subprocess.run(str(cl_call), shell=True, check=True)\n",
    "        \n",
    "    # Write a function that makes pairwise alignments\n",
    "    def align(self):\n",
    "        pass\n",
    "            \n",
    "    # Write a function that analyzes the alignment output and identifies variable\n",
    "    # positions\n",
    "    def find_variable_positions(self, first_in_frame = None):\n",
    "        \n",
    "        # Error if first in frame is not provided\n",
    "        if first_in_frame is None:\n",
    "            warnings.Warn(\"Not implemented\") \n",
    "                  \n",
    "    # Define properties\n",
    "    @property\n",
    "    def seqpairs(self):\n",
    "        return self._seqpairs\n",
    "    \n",
    "    @property\n",
    "    def index_plate(self):\n",
    "        return self._index_plate\n",
    "    \n",
    "    @property\n",
    "    def plate_nickname(self):\n",
    "        return self._plate_nickname\n",
    "    \n",
    "    @property\n",
    "    def well(self):\n",
    "        return self._well\n",
    "    \n",
    "    @property\n",
    "    def reference_sequence(self):\n",
    "        return self._reference_sequence\n",
    "    \n",
    "    @property\n",
    "    def fasta_loc(self):\n",
    "        return self._fasta_loc\n",
    "    \n",
    "    @property\n",
    "    def msa_loc(self):\n",
    "        return self._msa_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning sequences to wells...\n"
     ]
    }
   ],
   "source": [
    "def assign_seqpairs_to_well(filtered_seqpairs, bc_to_ref_plate_well, savedir):\n",
    "\n",
    "    # Loop over all seqpairs and assign to wells\n",
    "    print(\"Assigning sequences to wells...\")\n",
    "    well_pairs = {}\n",
    "    for pair in filtered_seqpairs:\n",
    "\n",
    "        # Grab the well ID and see if it is a real well. Continue\n",
    "        # if it is not. \"Fake\" wells are those that result from \n",
    "        # sequencing errors\n",
    "        well_id = (pair.f_barcode, pair.r_barcode)\n",
    "        if well_id not in bc_to_ref_plate_well:\n",
    "            continue\n",
    "        \n",
    "        # Check to see if we have seen this well already.\n",
    "        # If we have seen it, append to growing list. If we have not,\n",
    "        # start a new list\n",
    "        if well_id in well_pairs:\n",
    "            well_pairs[well_id].append(pair)\n",
    "        else:\n",
    "            well_pairs[well_id] = [pair]\n",
    "            \n",
    "    # Now build and return the well objects\n",
    "    return [Well(pair, bc_to_ref_plate_well[well_id], savedir) \n",
    "            for well_id, pair in well_pairs.items()] \n",
    "\n",
    "all_wells = assign_seqpairs_to_well(filtered_seqpairs, bc_to_ref_plate_well, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for well in all_wells:\n",
    "    well.write_fastas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align\n",
    "cl_call = ClustalOmegaCommandline(infile = \"./ParsedFilteredFastas/DI01-C04.fasta\", clustersize = len(all_wells[0].seqpairs),\n",
    "                                  outfile = \"./testAlign.fasta\", auto = True, force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07 s ± 41.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "subprocess.run(str(cl_call), shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DI01'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wells[0].index_plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C04'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wells[0].well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_wells[0].seqpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pairwise2.align.globalxs(all_wells[0].reference_sequence, all_wells[0].seqpairs[0].f_adapterless.seq, open = -2, \n",
    "                                extend = -1, one_alignment_only=True, penalize_end_gaps = False)[0]\n",
    "test2 = pairwise2.align.globalxs(all_wells[0].reference_sequence, all_wells[0].seqpairs[0].r_adapterless.seq, open = -2, \n",
    "                                extend = -1, one_alignment_only=True, penalize_end_gaps = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('seqA', 'seqB', 'score', 'start', 'end')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCACTGCAGAAACACTCAGTCGCTATTAGCGCCACGATGGGTCGGCTGNNNNNNGAACGGTATCCCGAAACGNNNAGCTTGNNNGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCCCTGTTGGCCTACGCCCGTAGT'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.seqA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCACTGCAGAAACACTCAGTCGCTATTAGCGCCACGATGGGTCGGCTGCCGCCGGAACGGTATCCCGAAACGGTTAGCTTGGGTGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCC---------------------'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.seqB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCACTGCAGAAACACTCAGTCGCTATTAGCGCCACGATGGGTCGGCTGNNNNNNGAACGGTATCCCGAAACGNNNAGCTTGNNNGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCCCTGTTGGCCTACGCCCGTAGT'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.seqA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------TCGCTATTAGCGCCACGATGGGTCGGCTGCCGCCGGAACGGTATCCCGAAACGGTTAGCTTGGGTGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCCCTGTTGGCCTACGCCCGTAGT'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.seqB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCACTGCAGAAACACTCAGTCGCTATTAGCGCCACGATGGGTCGGCTGCCGCCGGAACGGTATCCCGAAACGGTTAGCTTGGGTGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCC'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.seqB.lstrip(\"-\")\n",
    "test.seqB.rstrip(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into bowtie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastest is going to be pairwise align...just rework it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deseq(args):\n",
    "    \n",
    "    # Run all checks on args\n",
    "    \n",
    "    # Build reference sequence stuff\n",
    "    \n",
    "    # Parse files\n",
    "    \n",
    "    # If just analyzing, stop here\n",
    "    \n",
    "    # If just getting filtered fastq, stop here\n",
    "    \n",
    "    # If just getting MSAs, stop here\n",
    "    \n",
    "    # If getting decoupled alignment results, stop here\n",
    "    \n",
    "    # If getting paired alignment results, stop here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
