{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a development ground for the new alignment protocol. Note that the clustal omega version being used was downloaded on 10/26/2020 from \"http://www.clustal.org/omega/\" and was renamed to \"clustalo\" from the binary file clustalo-1.2.4-Ubuntu-x86_64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary modules\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align.Applications import ClustalOmegaCommandline\n",
    "from Bio import pairwise2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BARCODE_LENGTH = 7\n",
    "ADAPTER_LENGTH_F = 20\n",
    "ADAPTER_LENGTH_R = 19\n",
    "\n",
    "# Redefine the BioPython aligment function so that we can quicky change\n",
    "# parameters later\n",
    "def deseq_align(reference, query):\n",
    "    \n",
    "    # Redefine biopython aligment function (this is just for code neatness)\n",
    "    return pairwise2.align.globalxs(reference, query, open = -2, extend = -1,\n",
    "                                    one_alignment_only=True, penalize_end_gaps = False)[0]\n",
    "    \n",
    "\n",
    "# Define an object that holds BioPython SeqRecords\n",
    "class SeqPair():\n",
    "    \n",
    "    # Record that we don't have forward or reverse information yet. Record that\n",
    "    # we don't have alignment information yet\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Did sequence pass QC?\n",
    "        self._use_f = False\n",
    "        self._use_r = False\n",
    "        \n",
    "        # Did alignments pass QC?\n",
    "        self._use_f_alignment = False\n",
    "        self._use_r_alignment = False\n",
    "            \n",
    "    # Assign forward reads\n",
    "    def assign_f(self, f_record):\n",
    "        \n",
    "        # Build summary stats\n",
    "        self._f_barcode, self._f_len, self._f_average_q = self.calculate_read_stats(f_record)\n",
    "                \n",
    "        # Assign the forward barcode and the adapterless sequence\n",
    "        self._f_adapterless = f_record[(BARCODE_LENGTH + ADAPTER_LENGTH_F):]\n",
    "        \n",
    "        # Note that we have forward information\n",
    "        self._use_f = True\n",
    "    \n",
    "    # Assign a paired reverse read\n",
    "    def assign_r(self, r_record):\n",
    "        \n",
    "        # Build summary stats\n",
    "        self._r_barcode, self._r_len, self._r_average_q = self.calculate_read_stats(r_record)\n",
    "        \n",
    "        # Assign the reverse barcode and adapterless sequence. \n",
    "        # We want to have the reverse complement of this sequence to match\n",
    "        # the reference sequence\n",
    "        self._sliced_r = r_record[(BARCODE_LENGTH + ADAPTER_LENGTH_R):]\n",
    "        self._r_adapterless = self.sliced_r.reverse_complement(id = True, description = True)\n",
    "        \n",
    "        # Note that we have reverse information\n",
    "        self._use_r = True\n",
    "        \n",
    "    # Calculate summary stats for a read\n",
    "    def calculate_read_stats(self, record):\n",
    "        \n",
    "        # Calculate relevant summary stats needed by both forward and reverse methods\n",
    "        barcode = str(record.seq)[:BARCODE_LENGTH]\n",
    "        length = len(record)\n",
    "        average_quality = np.mean(record.letter_annotations[\"phred_quality\"])\n",
    "        \n",
    "        return barcode, length, average_quality\n",
    "    \n",
    "    # Write a function that performs QC on reads\n",
    "    def qc_reads(self, length_filter, q_cutoff):\n",
    "        \n",
    "        # Make sure forward reads pass the length and quality cutoff. Only run QC\n",
    "        # if we actually recorded a forward read.\n",
    "        if self.use_f:\n",
    "            if self.f_len < length_filter or self.f_average_q < q_cutoff:\n",
    "                self._use_f = False\n",
    "                \n",
    "        # Make sure reverse reads pass the length and quality cutoff. Only run QC\n",
    "        # if we actually recorded a forward read.\n",
    "        if self.use_r:\n",
    "            if self.r_len < length_filter or self._r_average_q < q_cutoff:\n",
    "                self._use_r = False\n",
    "    \n",
    "    # Align forward and reverse reads to a reference sequence\n",
    "    def align(self, reference):\n",
    "        \n",
    "        # Make a pairwise alignment. Only align the reads we are using.\n",
    "        if self.is_paired():\n",
    "            self._f_alignment = deseq_align(reference, self.f_adapterless.seq)\n",
    "            self._r_alignment = deseq_align(reference, self.r_adapterless.seq)\n",
    "            \n",
    "        # If we are only using forward read, handle this here\n",
    "        elif self.use_f:\n",
    "            self._f_alignment = deseq_align(reference, self.f_adapterless.seq)\n",
    "            self._r_alignment = None\n",
    "            \n",
    "        # If we are only using reverse read, handle this here\n",
    "        elif self.use_r:\n",
    "            self._f_alignment = None\n",
    "            self._r_alignment = deseq_align(reference, self.r_adapterless.seq)\n",
    "            \n",
    "        else:\n",
    "            raise AssertionError(\"No reads to align in reference.\")\n",
    "        \n",
    "    # Write a function that runs QC on an alignment. We automatically discard an alignment\n",
    "    # with an insertion or deletion. \n",
    "    def qc_alignment(self, forward_check = True):\n",
    "        \n",
    "        # By default, this is a good alignment. If it fails the qc tests, then it\n",
    "        # will become a bad alignment\n",
    "        good_alignment = True\n",
    "        \n",
    "        # Pull the appropriate alignment \n",
    "        test_alignment = self.f_alignment if forward_check else self.r_alignment\n",
    "        \n",
    "        # If the alignment is None, this is a bad alignment (the original sequence\n",
    "        # failed qc) and we cannot conitnue.\n",
    "        if test_alignment is None:\n",
    "            return False, -1\n",
    "        \n",
    "        # Pull the reference sequence and alignmed sequence\n",
    "        refseq = test_alignment.seqA\n",
    "        aligned_seq = test_alignment.seqB\n",
    "\n",
    "        # If there are any dashes in the reference sequence, we have a bad alignment\n",
    "        if \"-\" in refseq:\n",
    "            good_alignment = False\n",
    "\n",
    "        # Get the stripped down aligned sequences\n",
    "        lstripped = aligned_seq.lstrip(\"-\")\n",
    "        rstripped = aligned_seq.rstrip(\"-\")\n",
    "        \n",
    "        # If this is a forward check, dashes in the middle or to the left of the aligned\n",
    "        # sequence indicate a deletion or insertion\n",
    "        if forward_check:\n",
    "\n",
    "            # Check to see if we have an insertion or deletion\n",
    "            if len(lstripped) < len(aligned_seq) or \"-\" in rstripped:\n",
    "                good_alignment = False\n",
    "\n",
    "            # Get the first instance of a dash in the full sequence. This indicates the\n",
    "            # first character after the alignment ends\n",
    "            first_dash = lstripped.find(\"-\")\n",
    "\n",
    "            return good_alignment, first_dash\n",
    "\n",
    "        # If this is a reverse check, dashes in the middle or to the right of the aligned\n",
    "        # sequence indicate a deletion or insertion\n",
    "        else:\n",
    "\n",
    "            # Check to see if we have an insertion or deletion\n",
    "            if len(rstripped) < len(aligned_seq) or \"-\" in lstripped:\n",
    "                good_alignment = False\n",
    "\n",
    "            # Get the last instance of a dash in the full sequence. This indicates the last\n",
    "            # character index before the aligned sequence begins.\n",
    "            last_dash = rstripped.rfind(\"-\")\n",
    "\n",
    "            return good_alignment, last_dash\n",
    "\n",
    "    # Write a function that runs QC on a pair of alignments. This will set flags for whether\n",
    "    # or not an alignment is usable\n",
    "    def qc_alignments(self):\n",
    "        \n",
    "        # Run QC on the forward and reverse alignments\n",
    "        self._use_f_alignment, self._first_dash = self.qc_alignment(forward_check = True)\n",
    "        self._use_r_alignment, self._last_dash = self.qc_alignment(forward_check = False)\n",
    "        \n",
    "    # Build a composite alignment for paired ends\n",
    "    def build_paired_composite_alignment(self):\n",
    "        \n",
    "        # Both forward and reverse reads must pass aligment qc to enable this \n",
    "        assert self.is_paired_post_alignment_qc(), \"Cannot build composite from 1 read.\"\n",
    "        \n",
    "        # Grab the reference sequence, the aligned sequences, \n",
    "        # and the quality scores\n",
    "        refseq = self.f_alignment.seqA\n",
    "        reflength = len(refseq)\n",
    "        forward_seq = self.f_alignment.seqB\n",
    "        reverse_seq = self.r_alignment.seqB\n",
    "        forward_qual = np.array(self.f_adapterless.letter_annotations[\"phred_quality\"])\n",
    "        reverse_qual = np.array(self.r_adapterless.letter_annotations[\"phred_quality\"])\n",
    "\n",
    "        # Get the end of the f read. If it goes all the way to the end of the reference\n",
    "        # sequence, then the first non-f character is the length of the sequence\n",
    "        post_forward_dash_ind = reflength if self.first_dash == -1 else self.first_dash\n",
    "        last_forward_char_ind = post_forward_dash_ind - 1\n",
    "\n",
    "        # Get the beginning of the r read. If it starts from the beginning of the ference\n",
    "        # sequence, then the first non-r character is -1, so we don't actually need to\n",
    "        # make any adjustments\n",
    "        pre_reverse_dash_ind = self.last_dash\n",
    "        first_r_char_ind = pre_reverse_dash_ind + 1\n",
    "\n",
    "        # See if the forward and reverse overlap. If they don't overlap. Then the composite\n",
    "        # is just the forward DNA + dashes + reverse DNA\n",
    "        if post_forward_dash_ind <= pre_reverse_dash_ind:\n",
    "\n",
    "            # Calculate the number of dashes needed\n",
    "            n_dashes = pre_reverse_dash_indr - post_forward_dash_ind + 1\n",
    "\n",
    "            # Build the composite sequence between the two\n",
    "            composite_seq = \"\".join((forward_seq[:post_forward_dash_ind], \n",
    "                                   \"-\" * n_dashes,\n",
    "                                   reverse_seq[first_r_char_ind:]))\n",
    "\n",
    "            # Build the composite quality. The quality scores are not extended for the\n",
    "            # alignment, and so map directly to the pulled sequences.\n",
    "            composite_qual = np.concatenate((forward_qual,\n",
    "                                             np.full(n_dashes, np.inf),\n",
    "                                             reverse_qual))\n",
    "\n",
    "        # Otherwise, take the sequence with the highest quality in the overlapping region\n",
    "        else:\n",
    "\n",
    "            # Pull the forward up to the start of the reverse sequence\n",
    "            only_f_seq = forward_seq[:first_r_char_ind]\n",
    "            only_f_qual = forward_qual[:first_r_char_ind]\n",
    "\n",
    "            # Pull the reverse after the end point of forward. Quality scores only cover \n",
    "            # sequence (not alignment gaps), so we need to calculate where the qualities\n",
    "            # end for the reverse sequence.\n",
    "            only_r_seq = reverse_seq[post_forward_dash_ind:]\n",
    "            reverse_qual_break = len(reverse_qual) - len(only_r_seq)\n",
    "            only_r_qual = reverse_qual[reverse_qual_break:]\n",
    "\n",
    "            # Now compare the middle parts. Take the one with the higher sequence quality. \n",
    "            # The middle characters all fall \n",
    "            middle_f_seq = forward_seq[first_r_char_ind:post_forward_dash_ind]\n",
    "            middle_f_qual = forward_qual[first_r_char_ind:]\n",
    "            middle_r_seq = reverse_seq[first_r_char_ind:post_forward_dash_ind]\n",
    "            middle_r_qual = reverse_qual[:reverse_qual_break]\n",
    "\n",
    "            # The middle sequences should be equal in length (they might differ in sequence\n",
    "            # due to sequencing errors.  The quality scores should have the same length as well\n",
    "            middle_size = len(middle_f_seq)\n",
    "            assert middle_size == len(middle_r_seq)\n",
    "            assert middle_size == len(middle_f_qual)\n",
    "            assert middle_size == len(middle_r_qual)\n",
    "\n",
    "            # Build the composite middle sequence and quality\n",
    "            middle_seq = [None] * middle_size\n",
    "            middle_qual = np.zeros(middle_size, dtype = int)\n",
    "            quality_comparison = np.greater(middle_f_qual, middle_r_qual).astype(int)\n",
    "            for i in range(middle_size):\n",
    "\n",
    "                # If the reverse read has better quality, use that\n",
    "                if quality_comparison[i]:\n",
    "                    middle_seq[i] = middle_r_seq[i]\n",
    "                    middle_qual[i] = middle_r_qual[i]\n",
    "\n",
    "                # If the forward read has better quality, use that\n",
    "                else:\n",
    "                    middle_seq[i] = middle_f_seq[i]\n",
    "                    middle_qual[i] = middle_f_qual[i]\n",
    "\n",
    "            # Build the overall composite sequence and qualities. \n",
    "            composite_seq = \"\".join((only_f_seq, \"\".join(middle_seq), only_r_seq))\n",
    "            composite_qual = np.concatenate((only_f_qual, middle_qual, only_r_qual))\n",
    "            \n",
    "        # Check to be sure lengths are correct\n",
    "        assert reflength == len(composite_seq)\n",
    "        assert reflength == len(composite_qual)\n",
    "            \n",
    "        return composite_seq, composite_qual\n",
    "    \n",
    "    # Build a pairwise composite alignment for non-paired ends\n",
    "    def build_unpaired_composite_alignment(self):\n",
    "        \n",
    "        # First make sure that we are calling this function appropriately\n",
    "        assert not self.is_paired_post_alignment_qc(), \"This function only works for unpaired reads\"\n",
    "        \n",
    "        # Determine if it is forward or reverse reads\n",
    "        if self.use_f_alignment:\n",
    "            \n",
    "            # Get the length of the reference sequence\n",
    "            refseq = self.f_alignment.seqA\n",
    "            composite_length = len(refseq)\n",
    "            \n",
    "            # The composite sequence is just the aligned sequence\n",
    "            composite_seq = self.f_alignment.seqB\n",
    "            \n",
    "            # The qualities continue after the alignment. Add as many zeros as \n",
    "            # there are differences between existing qualities and the end of\n",
    "            # the sequence\n",
    "            forward_qual = self.f_adapterless.letter_annotations[\"phred_quality\"]\n",
    "            composite_qual = np.concatenate((forward_qual, \n",
    "                                             np.full(composite_length - len(forward_qual), np.inf)))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Get the length of the reference sequence\n",
    "            refseq = self.r_alignment.seqA\n",
    "            composite_length = len(refseq)\n",
    "            \n",
    "            # The composite sequence is just the aligned sequence\n",
    "            composite_seq = self.r_alignment.seqB\n",
    "            \n",
    "            # The qualities must be before the alignment. Prepend as many zeros\n",
    "            # as there are differences between existing qualities and the end of \n",
    "            # the sequence\n",
    "            reverse_qual = self.r_adapterless.letter_annotations[\"phred_quality\"]\n",
    "            composite_qual = np.concatenate((np.full(composite_length - len(reverse_qual), np.inf),\n",
    "                                             reverse_qual))\n",
    "            \n",
    "        # Assert that everything is the expected length\n",
    "        assert composite_length == len(composite_seq)\n",
    "        assert composite_length == len(composite_qual)\n",
    "            \n",
    "        return composite_seq, composite_qual\n",
    "    \n",
    "    # Write a function that builds a composite sequence regardless of alignment type\n",
    "    def build_composite_alignment(self):\n",
    "        \n",
    "        # Complicated composite if this is paired end\n",
    "        if self.is_paired_post_alignment_qc():\n",
    "            return self.build_paired_composite_alignment()\n",
    "        \n",
    "        # Simple composite if this is not paired end\n",
    "        else:\n",
    "            return self.build_unpaired_composite_alignment()\n",
    "        \n",
    "    # Write a function for extracting information from the alignment\n",
    "    def analyze_alignment(self, inframe_ind, ref_len, n_aas, qual_thresh):\n",
    "        \n",
    "        # Pull the composite alignment for the sequence\n",
    "        composite_sequence, composite_qual = self.build_composite_alignment()\n",
    "\n",
    "        # Create matrices in which to store counts\n",
    "        bp_counts = np.zeros([6, ref_len], dtype = int)\n",
    "        aa_counts = np.zeros([23, n_aas], dtype = int)\n",
    "\n",
    "        # Loop over the composite sequence up to the in-frame part\n",
    "        for base_ind, (bp, qual) in enumerate(zip(composite_sequence[:inframe_ind],\n",
    "                                                  composite_qual[:inframe_ind])):\n",
    "\n",
    "            # Only record counts if we meet a quality threshold\n",
    "            if qual >= qual_thresh:\n",
    "                bp_counts[BP_TO_IND[bp], base_ind] += 1\n",
    "\n",
    "        # Initialize variables for holding codon information\n",
    "        aa_counter = 0\n",
    "        record_aa = True\n",
    "        codon = [None] * 3\n",
    "        codon_counter = 0\n",
    "        \n",
    "        # Loop over the remaining sequence that is in frame\n",
    "        for inframe_counter, (bp, qual) in enumerate(zip(composite_sequence[inframe_ind:],\n",
    "                                                         composite_qual[inframe_ind:])):\n",
    "\n",
    "            # Update the base ind (this continues from our previous loop)\n",
    "            base_ind += 1\n",
    "\n",
    "            # If the inframe counter is divisible by 3, is not 0 rest the codon counter\n",
    "            if inframe_counter %3 == 0 and inframe_counter != 0:\n",
    "\n",
    "                # If all members of the codon passed quality control record\n",
    "                if record_aa:\n",
    "                    \n",
    "                    # Join the characters\n",
    "                    joined_codon = \"\".join(codon)\n",
    "                    \n",
    "                    # If this is in a gap, record gap\n",
    "                    if \"-\" in joined_codon:\n",
    "                        aa = \"-\"\n",
    "                    \n",
    "                    # If it isn't in the codon table, record question mark\n",
    "                    elif joined_codon not in CODON_TABLE:\n",
    "                        aa = \"?\"\n",
    "                    \n",
    "                    else:\n",
    "                        aa = CODON_TABLE[joined_codon]\n",
    "                    \n",
    "                    # Add to counts\n",
    "                    aa_counts[AA_TO_IND[aa], aa_counter] += 1\n",
    "\n",
    "                # Reset all codon related variables and increment the aa counter\n",
    "                aa_counter += 1\n",
    "                record_aa = True\n",
    "                codon = [None] * 3\n",
    "                codon_counter = 0\n",
    "\n",
    "            # Only record counts if we meet a quality threshold\n",
    "            if qual >= qual_thresh:\n",
    "                bp_counts[BP_TO_IND[bp], base_ind] += 1\n",
    "                codon[codon_counter] = bp\n",
    "\n",
    "            # If we don't meet a quality threshold, then throw a flag to\n",
    "            # not record the aa in this codon\n",
    "            else:\n",
    "                record_aa = False\n",
    "\n",
    "            # Increment the codon counter\n",
    "            codon_counter += 1\n",
    "            \n",
    "        # Run a check on the count. A sum across the 0th axis should\n",
    "        # return all ones and zeros, as we should never count two bases or two\n",
    "        # amino acids in one position\n",
    "        bp_test = np.sum(bp_counts, axis = 0)\n",
    "        aa_test = np.sum(aa_counts, axis = 0)\n",
    "        assert np.all(np.logical_or(bp_test == 1, bp_test == 0)), \"Double counting bases\"\n",
    "        assert np.all(np.logical_or(aa_test == 1, aa_test == 0)), \"Double counting amino acids\"\n",
    "            \n",
    "        # Return the filled out count matrices\n",
    "        return bp_counts, aa_counts\n",
    "    \n",
    "    # Write a function that returns read lengths\n",
    "    def read_lengths(self):\n",
    "        if self.is_paired():\n",
    "            return [self.f_len, self.r_len]\n",
    "        elif self.use_f:\n",
    "            return [self.f_len, np.nan]\n",
    "        elif self.use_r:\n",
    "            return [np.nan, self.r_len]\n",
    "        else:\n",
    "            raise AssertionError(\"No reads for which to return lengths.\")\n",
    "    \n",
    "    # Check to see if we are using both sequences\n",
    "    def is_paired(self):\n",
    "        if self.use_r and self.use_f:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # Check to see if we have no sequences aligned\n",
    "    def is_dud(self):\n",
    "        if not (self.use_r or self.use_f):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # Check to see if both alignments pass QC\n",
    "    def is_paired_post_alignment_qc(self):\n",
    "        if self.use_f_alignment and self.use_r_alignment:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # Check to see if we have no alignments that pass\n",
    "    def is_dud_post_alignment_qc(self):\n",
    "        if not(self.use_f_alignment or self.use_r_alignment):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # Make all the properties\n",
    "    @property\n",
    "    def use_f(self):\n",
    "        return self._use_f\n",
    "    \n",
    "    @property\n",
    "    def use_r(self):\n",
    "        return self._use_r\n",
    "    \n",
    "    @property\n",
    "    def use_f_alignment(self):\n",
    "        return self._use_f_alignment\n",
    "    \n",
    "    @property\n",
    "    def use_r_alignment(self):\n",
    "        return self._use_r_alignment\n",
    "        \n",
    "    @property\n",
    "    def f_barcode(self):\n",
    "        return self._f_barcode\n",
    "    \n",
    "    @property\n",
    "    def f_len(self):\n",
    "        return self._f_len\n",
    "    \n",
    "    @property\n",
    "    def f_average_q(self):\n",
    "        return self._f_average_q\n",
    "    \n",
    "    @property\n",
    "    def f_adapterless(self):\n",
    "        return self._f_adapterless\n",
    "    \n",
    "    @property\n",
    "    def r_barcode(self):\n",
    "        return self._r_barcode\n",
    "    \n",
    "    @property\n",
    "    def r_len(self):\n",
    "        return self._r_len\n",
    "    \n",
    "    @property\n",
    "    def r_average_q(self):\n",
    "        return self._r_average_q\n",
    "    \n",
    "    @property\n",
    "    def sliced_r(self):\n",
    "        return self._sliced_r\n",
    "    \n",
    "    @property\n",
    "    def r_adapterless(self):\n",
    "        return self._r_adapterless\n",
    "    \n",
    "    @property\n",
    "    def f_alignment(self):\n",
    "        return self._f_alignment\n",
    "    \n",
    "    @property\n",
    "    def r_alignment(self):\n",
    "        return self._r_alignment\n",
    "    \n",
    "    @property\n",
    "    def first_dash(self):\n",
    "        return self._first_dash\n",
    "    \n",
    "    @property\n",
    "    def last_dash(self):\n",
    "        return self._last_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading forward reads...\n",
      "Loading reverse reads...\n"
     ]
    }
   ],
   "source": [
    "# Write a function for loading and pairing fastq files\n",
    "def load_fastq(f_loc, r_loc):\n",
    "\n",
    "    # Create a dictionary that links id to sequence object\n",
    "    id_to_reads = {}\n",
    "    print(\"Loading forward reads...\")\n",
    "    all_f_recs = list(SeqIO.parse(f_loc, \"fastq\"))\n",
    "    for f_record in all_f_recs:\n",
    "        temp_record = SeqPair()\n",
    "        temp_record.assign_f(f_record)\n",
    "        id_to_reads[f_record.id] = temp_record\n",
    "    \n",
    "    # Associate reverse reads with the forward\n",
    "    print(\"Loading reverse reads...\")\n",
    "    all_r_recs = list(SeqIO.parse(r_loc, \"fastq\"))\n",
    "    for r_record in all_r_recs:\n",
    "\n",
    "        # If there is no partern in id_to_reads, create a new object \n",
    "        # and continue\n",
    "        if r_record.id not in id_to_reads:\n",
    "            temp_record = SeqPair()\n",
    "            temp_record.assign_r(r_record)\n",
    "            id_to_reads[r_record.id] = temp_record\n",
    "\n",
    "        # Otherwise, attach the reverse record\n",
    "        else:\n",
    "            id_to_reads[r_record.id].assign_r(r_record)\n",
    "            \n",
    "    # Only keep records that have a partner\n",
    "    return list(id_to_reads.values())\n",
    "\n",
    "# Load fastq files\n",
    "all_seqpairs = load_fastq(\"./TestData/20200205_ssSeq/CHL2_S199_L001_R1_001.fastq\",\n",
    "                          \"./TestData/20200205_ssSeq/CHL2_S199_L001_R2_001.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running read qc...\n"
     ]
    }
   ],
   "source": [
    "# Write a function for filtering out bad seqpairs\n",
    "def qc_seqpairs(all_seqpairs, read_length = None, length_cutoff = 0.9, q_cutoff = 30):\n",
    "    \n",
    "    print(\"Running read qc...\")\n",
    "    \n",
    "    # If we don't have the read length determine it\n",
    "    if read_length is None:\n",
    "\n",
    "        # Get the most common read length. We will assign this as our read length\n",
    "        all_readlengths = np.array([seqpair.read_lengths() for seqpair in all_seqpairs])\n",
    "        read_length = ss.mode(all_readlengths, axis = None, nan_policy = \"omit\").mode[0]\n",
    "        \n",
    "    # Calculate the read filter\n",
    "    read_filter = read_length * length_cutoff\n",
    "        \n",
    "    # Run QC on every read\n",
    "    for seqpair in all_seqpairs:\n",
    "        seqpair.qc_reads(read_filter, q_cutoff)\n",
    "    \n",
    "    # Eliminate any duds, which are those seqpairs with both a forward and a reverse that failed qc\n",
    "    no_duds = tuple(filter(lambda x: not x.is_dud(), all_seqpairs))\n",
    "    \n",
    "    return no_duds\n",
    "\n",
    "filtered_seqpairs = qc_seqpairs(all_seqpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_WELLS = {'A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', \n",
    "                 'A10', 'A11', 'A12', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', \n",
    "                 'B07', 'B08', 'B09', 'B10', 'B11', 'B12', 'C01', 'C02', 'C03', \n",
    "                 'C04', 'C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', \n",
    "                 'D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', \n",
    "                 'D10', 'D11', 'D12', 'E01', 'E02', 'E03', 'E04', 'E05', 'E06', \n",
    "                 'E07', 'E08', 'E09', 'E10', 'E11', 'E12', 'F01', 'F02', 'F03', \n",
    "                 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11', 'F12', \n",
    "                 'G01', 'G02', 'G03', 'G04', 'G05', 'G06', 'G07', 'G08', 'G09', \n",
    "                 'G10', 'G11', 'G12', 'H01', 'H02', 'H03', 'H04', 'H05', 'H06', \n",
    "                 'H07', 'H08', 'H09', 'H10', 'H11', 'H12'}\n",
    "\n",
    "BP_TO_IND = {\"A\": 0, \n",
    "            \"T\": 1,\n",
    "            \"C\": 2,\n",
    "            \"G\": 3,\n",
    "            \"N\": 4,\n",
    "            \"-\": 5}\n",
    "\n",
    "AA_TO_IND = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, \n",
    "             'H': 8, 'I': 9, 'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, \n",
    "             'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19, '*': 20, '?': 21, '-': 22}\n",
    "\n",
    "CODON_TABLE = {'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L', 'TCT': 'S', \n",
    "               'TCC': 'S', 'TCA': 'S', 'TCG': 'S', 'TAT': 'Y', 'TAC': 'Y', \n",
    "               'TGT': 'C', 'TGC': 'C', 'TGG': 'W', 'CTT': 'L', 'CTC': 'L', \n",
    "               'CTA': 'L', 'CTG': 'L', 'CCT': 'P', 'CCC': 'P', 'CCA': 'P', \n",
    "               'CCG': 'P', 'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q', \n",
    "               'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R', 'ATT': 'I', \n",
    "               'ATC': 'I', 'ATA': 'I', 'ATG': 'M', 'ACT': 'T', 'ACC': 'T', \n",
    "               'ACA': 'T', 'ACG': 'T', 'AAT': 'N', 'AAC': 'N', 'AAA': 'K', \n",
    "               'AAG': 'K', 'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R', \n",
    "               'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V', 'GCT': 'A', \n",
    "               'GCC': 'A', 'GCA': 'A', 'GCG': 'A', 'GAT': 'D', 'GAC': 'D', \n",
    "               'GAA': 'E', 'GAG': 'E', 'GGT': 'G', 'GGC': 'G', 'GGA': 'G', \n",
    "               'GGG': 'G', 'TAG': '*', 'TAA': '*', 'TGA': '*'}\n",
    "\n",
    "# Load the index map and reference sequencefile\n",
    "index_map = pd.read_csv(\"/home/brucejwittmann/GitRepos/ssSeq/ssSeqSupport/IndexMap.csv\")\n",
    "ref_seq_crude = pd.read_csv(\"/home/brucejwittmann/GitRepos/ssSeq/AlignmentDev/TestData/20200205_ssSeq/RefSeqs.csv\")\n",
    "\n",
    "# Expand each reference sequence\n",
    "updated_ref_array = []\n",
    "for row in ref_seq_crude.itertuples(index = False):\n",
    "    updated_ref_array.extend([[row.PlateName, row.IndexPlate, well, row.ReferenceSequence, row.InFrameBase]\n",
    "                             for well in ALLOWED_WELLS])\n",
    "    \n",
    "# Define the complete reference sequence dataframe\n",
    "complete_ref_seq = pd.DataFrame(updated_ref_array, columns = (\"PlateName\", \"IndexPlate\", \"Well\", \"ReferenceSequence\", \"InFrameBase\"))\n",
    "\n",
    "# Join on plate and well\n",
    "merged_dfs = complete_ref_seq.merge(index_map, on = (\"IndexPlate\", \"Well\"))\n",
    "\n",
    "# Map barcode to reference sequence, plate, and well\n",
    "bc_to_ref_plate_well = {(row.FBC, row.RBC): {\"IndexPlate\": row.IndexPlate,\n",
    "                                             \"PlateNickname\": row.PlateName,\n",
    "                                             \"Well\": row.Well,\n",
    "                                             \"ReferenceSequence\": row.ReferenceSequence,\n",
    "                                            \"InFrameBase\": row.InFrameBase}\n",
    "                       for row in merged_dfs.itertuples(index = False)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Well():\n",
    "    \n",
    "    # Initialization assigns attributes, reference sequences, and sequence pairs\n",
    "    def __init__(self, seqpairs, refseq_df_info, save_dir):\n",
    "        \n",
    "        # Assign the sequence pairs as an attribute and unpack the refseq info\n",
    "        self._all_seqpairs = seqpairs\n",
    "        self._index_plate = refseq_df_info[\"IndexPlate\"]\n",
    "        self._plate_nickname = refseq_df_info[\"PlateNickname\"]\n",
    "        self._well = refseq_df_info[\"Well\"]\n",
    "        self._reference_sequence = refseq_df_info[\"ReferenceSequence\"]\n",
    "        self._ref_len = len(self.reference_sequence)\n",
    "        self._in_frame_ind = refseq_df_info[\"InFrameBase\"] - 1 #Input is 1-indexed, so subtract 1\n",
    "        \n",
    "        # Generate save locations for alignment files\n",
    "        self._fasta_loc = os.path.join(save_dir, \"ParsedFilteredFastqs\")\n",
    "        self._alignment_loc = os.path.join(save_dir, \"Alignments\", \n",
    "                                       f\"{self.index_plate}-{self.well}.txt\")\n",
    "        \n",
    "        # Get the number of aas in the reference sequence\n",
    "        self._n_aas = (self.ref_len - self.in_frame_ind) // 3\n",
    "        \n",
    "    # Write a function that outputs adapterless fastq files for all paired end seqpairs\n",
    "    # Note that the reverse complement of \n",
    "    def write_fastqs(self):\n",
    "        \n",
    "        # Identify the paired end sequence pairs\n",
    "        paired_end_alignments = tuple(filter(lambda x: x.is_paired_post_alignment_qc(), self.all_seqpairs))\n",
    "        \n",
    "        # Build a list of sequences to save\n",
    "        f_records_to_save = [seqpair.f_adapterless for seqpair in paired_end_alignments]\n",
    "        r_records_to_save = [seqpair.sliced_r for seqpair in paired_end_alignments]\n",
    "        assert len(f_records) == len(r_records), \"Mismatch in number of paired ends\"\n",
    "            \n",
    "        # Save the records\n",
    "        with open(os.path.join(self.fasta_loc, \"F\", f\"{self.index_plate}-{self.well}_R1.fastq\"), \"w\") as f:\n",
    "            SeqIO.write(f_records_to_save, f, \"fastq\")\n",
    "        with open(os.path.join(self.fasta_loc, \"R\", f\"{self.index_plate}-{self.well}_R2.fastq\"), \"w\") as f:\n",
    "            SeqIO.write(f_records_to_save, f, \"fastq\")\n",
    "            \n",
    "    # Write a function that makes pairwise and runs qc on pairwise alignments and then identifies usable\n",
    "    # and paired alignments\n",
    "    def align(self):\n",
    "        \n",
    "        # Run alignment on all seqpairs\n",
    "        for seqpair in self.all_seqpairs:\n",
    "            seqpair.align(self.reference_sequence)\n",
    "            seqpair.qc_alignments()\n",
    "        \n",
    "        # Identify seqpairs that have at least one read passing alignment QC\n",
    "        self._non_dud_alignments = tuple(filter(lambda x: not x.is_dud_post_alignment_qc(), self.all_seqpairs))\n",
    "                \n",
    "    # Write a function that analyzes alignments to generate count matrices\n",
    "    def analyze_alignments(self, qual_thresh):\n",
    "\n",
    "        # Create matrices in which to store counts\n",
    "        n_non_duds = len(self.non_dud_alignments)\n",
    "        self._bp_counts = np.zeros([n_non_duds, 6, self.ref_len], dtype = int)\n",
    "        self._aa_counts = np.zeros([n_non_duds, 23, self.n_aas], dtype = int)\n",
    "        \n",
    "        # Loop over all non-dud seqpairs and record counts for each aa and sequence\n",
    "        for pair_ind, seqpair in enumerate(self.non_dud_alignments):\n",
    "            self._bp_counts[pair_ind], self._aa_counts[pair_ind] = seqpair.analyze_alignment(self.in_frame_ind, \n",
    "                                                                                             self.ref_len,\n",
    "                                                                                             self.n_aas,\n",
    "                                                                                             qual_thresh) \n",
    "    \n",
    "    # Write a function to calculate the expected reference amino acid and base sequences\n",
    "    def calculate_expected_arrays(self):\n",
    "    \n",
    "        # Create arrays for storing expected results. \n",
    "        expected_bps = np.zeros([6, self.ref_len], dtype = int)\n",
    "        expected_aas = np.zeros([22, self.n_aas], dtype = int)\n",
    "\n",
    "        # Loop over the reference sequence and record expected basepairs\n",
    "        for bp_ind, bp in enumerate(self.reference_sequence):\n",
    "            expected_bps[BP_TO_IND[bp], bp_ind] += 1\n",
    "\n",
    "        # Caculate last readable bp for translation\n",
    "        last_readable_bp = self.in_frame_ind + self.n_aas * 3\n",
    "        \n",
    "        # Loop over the codons in the reference sequence and record\n",
    "        aa_counter = 0\n",
    "        for chunker in range(self.in_frame_ind, last_readable_bp, 3):\n",
    "\n",
    "            # Identify the codon and translate\n",
    "            codon = self.reference_sequence[chunker: chunker + 3]\n",
    "            expected_aa = \"?\" if codon not in CODON_TABLE else CODON_TABLE[codon]\n",
    "\n",
    "            # Record and increment counter\n",
    "            expected_aas[AA_TO_IND[expected_aa], aa_counter] += 1\n",
    "            aa_counter += 1\n",
    "            \n",
    "        # Make sure we are not double counting and that we are counting everything\n",
    "        bp_test = np.sum(expected_bps, axis = 0)\n",
    "        aa_test = np.sum(expected_aas, axis = 0)\n",
    "        assert np.all(bp_test == 1), \"Expected bp calculation is wrong\"\n",
    "        assert np.all(aa_test == 1), \"Expected aa calculation is wrong\"\n",
    "            \n",
    "        return expected_bps, expected_aas\n",
    "                        \n",
    "    # Write a function that analyzes the alignment output and identifies variable\n",
    "    # positions\n",
    "    def find_variable_positions(self):\n",
    "        pass\n",
    "        # Calculate the expected aa and bp frequencies given the reference sequence\n",
    "#         expected_aa_seq = self.re\n",
    "        \n",
    "        \n",
    "    # Define properties\n",
    "    @property\n",
    "    def all_seqpairs(self):\n",
    "        return self._all_seqpairs\n",
    "    \n",
    "    @property\n",
    "    def index_plate(self):\n",
    "        return self._index_plate\n",
    "    \n",
    "    @property\n",
    "    def plate_nickname(self):\n",
    "        return self._plate_nickname\n",
    "    \n",
    "    @property\n",
    "    def well(self):\n",
    "        return self._well\n",
    "    \n",
    "    @property\n",
    "    def reference_sequence(self):\n",
    "        return self._reference_sequence\n",
    "    \n",
    "    @property\n",
    "    def ref_len(self):\n",
    "        return self._ref_len\n",
    "    \n",
    "    @property\n",
    "    def n_aas(self):\n",
    "        return self._n_aas\n",
    "    \n",
    "    @property\n",
    "    def in_frame_ind(self):\n",
    "        return self._in_frame_ind\n",
    "    \n",
    "    @property\n",
    "    def fasta_loc(self):\n",
    "        return self._fasta_loc\n",
    "    \n",
    "    @property\n",
    "    def alignment_loc(self):\n",
    "        return self._alignment_loc\n",
    "        \n",
    "    @property\n",
    "    def non_dud_alignments(self):\n",
    "        return self._non_dud_alignments\n",
    "    \n",
    "    @property\n",
    "    def bp_counts(self):\n",
    "        return self._bp_counts\n",
    "    \n",
    "    @property\n",
    "    def aa_counts(self):\n",
    "        return self._aa_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning sequences to wells...\n"
     ]
    }
   ],
   "source": [
    "def assign_seqpairs_to_well(filtered_seqpairs, bc_to_ref_plate_well, savedir):\n",
    "\n",
    "    # Loop over all seqpairs and assign to wells\n",
    "    print(\"Assigning sequences to wells...\")\n",
    "    well_pairs = {}\n",
    "    for pair in filtered_seqpairs:\n",
    "\n",
    "        # Grab the well ID and see if it is a real well. Continue\n",
    "        # if it is not. \"Fake\" wells are those that result from \n",
    "        # sequencing errors\n",
    "        well_id = (pair.f_barcode, pair.r_barcode)\n",
    "        if well_id not in bc_to_ref_plate_well:\n",
    "            continue\n",
    "        \n",
    "        # Check to see if we have seen this well already.\n",
    "        # If we have seen it, append to growing list. If we have not,\n",
    "        # start a new list\n",
    "        if well_id in well_pairs:\n",
    "            well_pairs[well_id].append(pair)\n",
    "        else:\n",
    "            well_pairs[well_id] = [pair]\n",
    "            \n",
    "    # Now build and return the well objects\n",
    "    return [Well(pair, bc_to_ref_plate_well[well_id], savedir) \n",
    "            for well_id, pair in well_pairs.items()] \n",
    "\n",
    "all_wells = assign_seqpairs_to_well(filtered_seqpairs, bc_to_ref_plate_well, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a single well for testing\n",
    "testwell = all_wells[0]\n",
    "\n",
    "# Align\n",
    "testwell.align()\n",
    "testwell.analyze_alignments(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_bp, expected_aa = testwell.calculate_expected_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 6, 144)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testwell.bp_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_array = expected_bp\n",
    "test_array = testwell.bp_counts\n",
    "\n",
    "\n",
    "# Get the counts for the array\n",
    "by_unit_counts = test_array.sum(axis=0)\n",
    "\n",
    "# Now get the total counts of real bases/amino acids. This means that\n",
    "# gaps are ignored; unknown characters are allowed. We ignore gaps because\n",
    "# the only gaps present are those at the beginning or end of the sequence;\n",
    "# any gaps in the middle are not looked at for alignments\n",
    "by_position_counts = by_unit_counts[:-1].sum(axis=0)\n",
    "\n",
    "# Calculate frequency. Again, ignore gaps.\n",
    "by_unit_frequency = by_unit_counts[:-1] / by_position_counts\n",
    "\n",
    "# Now compare to the expected array\n",
    "difference_from_expectation_absolute = np.abs(by_unit_frequency - expected_array[:-1])\n",
    "average_difference_from_expectation = np.sum(difference_from_expectation_absolute, axis = 0)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_difference_from_expectation >= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCACTGCAGAAACACTCAGTCGCTATTAGCGCCACGATGGGTCGGCTGNNNNNNGAACGGTATCCCGAAACGNNNAGCTTGNNNGAACTTCCTGAGAGACAGATACACAAGCTTGCGTCGGCCCTGTTGGCCTACGCCCGTAGT'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testwell.reference_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_position_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_unit_frequency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_unit_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_aa_counts = testwell.aa_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_aa_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_position_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pair.use_f_alignment and not pair.is_paired_post_alignment_qc() for pair in testwell.all_seqpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pair.use_r_alignment and not pair.is_paired_post_alignment_qc() for pair in testwell.all_seqpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqpair in enumerate(testwell.non_dud_alignments):\n",
    "#     try:\n",
    "    seqpair.analyze_alignment(testwell.in_frame_ind, testwell.ref_len,\n",
    "                          testwell.n_aas, 30)\n",
    "#     except:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deseq(args):\n",
    "    \n",
    "    # Run all checks on args\n",
    "    \n",
    "    # Build reference sequence stuff\n",
    "    \n",
    "    # Parse files\n",
    "    \n",
    "    # If just analyzing, stop here\n",
    "    \n",
    "    # If just getting filtered fastq, stop here\n",
    "    \n",
    "    # If just getting MSAs, stop here\n",
    "    \n",
    "    # If getting decoupled alignment results, stop here\n",
    "    \n",
    "    # If getting paired alignment results, stop here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
